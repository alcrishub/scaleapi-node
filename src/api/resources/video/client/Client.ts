/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as environments from "../../../../environments";
import * as core from "../../../../core";
import { ScaleApi } from "@fern-api/scale";
import urlJoin from "url-join";
import * as serializers from "../../../../serialization";
import * as errors from "../../../../errors";

export declare namespace Client {
    interface Options {
        environment?: environments.ScaleApiEnvironment | string;
        token?: core.Supplier<core.BearerToken>;
    }
}

export class Client {
    constructor(private readonly options: Client.Options) {}

    /**
     * This endpoint creates a `videoplaybackannotation` task. In this task, we will view the given video file and draw annotation around the specified objects. You are required to provide a URL to the video file as the `attachment`. It can be in `mp4`, `webm`, or `ogg` format. You can optionally provide additional markdown-enabled or Google Doc-based [instructions](https://scale.com/docs/instructions) via the `instruction` parameter. You may optionally specify a `frame_rate`, which will determine how many frames per second will be used to annotate the given video. The default value is `1`. You may also optionally specify `events_to_annotate`, a list of strings describing [events section](/reference/events) to annotate in the video. If the request is successful, Scale will return the generated task object, at which point you should store the `task_id` to have a permanent reference to the task.
     */
    public async createPlaybackAnnotation(
        request: ScaleApi.VideoPlaybackAnnotationRequest
    ): Promise<ScaleApi.VideoPlaybackAnnotationResponse> {
        const _response = await core.fetcher({
            url: urlJoin(
                this.options.environment ?? environments.ScaleApiEnvironment.Production,
                "task/videoplaybackannotation"
            ),
            method: "POST",
            headers: {
                Authorization: core.BearerToken.toAuthorizationHeader(await core.Supplier.get(this.options.token)),
            },
            body: await serializers.VideoPlaybackAnnotationRequest.json(request),
        });
        if (_response.ok) {
            return await serializers.VideoPlaybackAnnotationResponse.parse(
                _response.body as serializers.VideoPlaybackAnnotationResponse.Raw
            );
        }

        if (_response.error.reason === "status-code") {
            throw new errors.ScaleApiError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.ScaleApiError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.ScaleApiTimeoutError();
            case "unknown":
                throw new errors.ScaleApiError({
                    message: _response.error.errorMessage,
                });
        }
    }

    /**
     * ### **Note: Scale Video is only available for our Enterprise customers**. If you want to learn more, please contact our [sales team](https://scale.com/sales). This endpoint creates a `videoannotation` task. Given a series of images sampled from a video (which we will refer to as "frames"), Scale will annotate each frame with the Geometries (`box`, `polygon`, `line`, `point`, `cuboid,` and `ellipse`) you specify. The required parameter for this task is `geometries`. You can optionally provide additional markdown-enabled or Google Doc-based [instructions](https://scale.com/docs/instructions) via the `instruction` parameter. You may also optionally specify `events_to_annotate`, a list of strings describing [events section](/reference/events) to annotate in the video. If the request is successful, Scale will return the generated task object, at which point you should store the `task_id` to have a permanent reference to the task.
     */
    public async createGeneralAnnotation(
        request: ScaleApi.VideoPlaybackAnnotationRequest
    ): Promise<ScaleApi.VideoPlaybackAnnotationResponse> {
        const _response = await core.fetcher({
            url: urlJoin(
                this.options.environment ?? environments.ScaleApiEnvironment.Production,
                "task/videoannotation"
            ),
            method: "POST",
            headers: {
                Authorization: core.BearerToken.toAuthorizationHeader(await core.Supplier.get(this.options.token)),
            },
            body: await serializers.VideoPlaybackAnnotationRequest.json(request),
        });
        if (_response.ok) {
            return await serializers.VideoPlaybackAnnotationResponse.parse(
                _response.body as serializers.VideoPlaybackAnnotationResponse.Raw
            );
        }

        if (_response.error.reason === "status-code") {
            throw new errors.ScaleApiError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
            });
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.ScaleApiError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                });
            case "timeout":
                throw new errors.ScaleApiTimeoutError();
            case "unknown":
                throw new errors.ScaleApiError({
                    message: _response.error.errorMessage,
                });
        }
    }
}
